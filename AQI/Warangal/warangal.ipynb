{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error,mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrg_so2=pd.read_excel(r'Warangal_so2.xlsx')\n",
    "wrg_nox=pd.read_excel(r'Warangal_no2.xlsx')\n",
    "wrg_pm10=pd.read_excel(r'Warangal_PM10.xlsx')\n",
    "wrg_aqi=pd.read_excel(r'Warangal_aqi.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling the null values row-wise as there seems to more yearly relation than monthly relation for each pollutant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,7):\n",
    "    wrg_so2.iloc[i,1:]=wrg_so2.iloc[i,1:].fillna(wrg_so2.iloc[i,1:].mean())\n",
    "    wrg_nox.iloc[i,1:]=wrg_nox.iloc[i,1:].fillna(wrg_nox.iloc[i,1:].mean())\n",
    "    wrg_pm10.iloc[i,1:]=wrg_pm10.iloc[i,1:].fillna(wrg_pm10.iloc[i,1:].mean())\n",
    "    wrg_aqi.iloc[i,1:]=wrg_aqi.iloc[i,1:].fillna(wrg_aqi.iloc[i,1:].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganizing the data for a combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrg_so2 = wrg_so2.melt(id_vars=[\"Year\"], var_name=\"Month\", value_name=\"SO2\")\n",
    "wrg_nox = wrg_nox.melt(id_vars=[\"Year\"], var_name=\"Month\", value_name=\"NOX\")\n",
    "wrg_pm10 = wrg_pm10.melt(id_vars=[\"Year\"], var_name=\"Month\", value_name=\"PM10\")\n",
    "wrg_aqi = wrg_aqi.melt(id_vars=[\"Year\"], var_name=\"Month\", value_name=\"AQI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing the data for better model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM10</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>76.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>75.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-01</th>\n",
       "      <td>72.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01</th>\n",
       "      <td>63.0</td>\n",
       "      <td>21.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>63.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>73.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-01</th>\n",
       "      <td>84.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>84.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01</th>\n",
       "      <td>57.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-01</th>\n",
       "      <td>60.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>55.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>55.134376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-01</th>\n",
       "      <td>65.0</td>\n",
       "      <td>34.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>69.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PM10   NOX  SO2        AQI\n",
       "2016-01-01  76.0  26.0  7.0  75.777778\n",
       "2016-02-01  72.0  19.0  7.0  72.111111\n",
       "2016-03-01  63.0  21.8  7.1  63.111111\n",
       "2016-04-01  73.0  20.0  7.0  73.370370\n",
       "2016-05-01  84.0  19.0  8.0  84.111111\n",
       "...          ...   ...  ...        ...\n",
       "2021-07-01  57.0  28.7  5.8  57.000000\n",
       "2021-08-01  60.0  32.7  6.8  60.000000\n",
       "2021-09-01  55.0  31.2  7.3  55.134376\n",
       "2021-11-01  65.0  34.3  8.3  65.000000\n",
       "2021-12-01  69.0  31.0  7.3  69.000000\n",
       "\n",
       "[66 rows x 4 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrg_poll = pd.merge(wrg_pm10, wrg_nox, on=['Month','Year'])\n",
    "wrg_poll = pd.merge(wrg_poll, wrg_so2, on=['Month','Year'])\n",
    "wrg_final=pd.merge(wrg_poll,wrg_aqi,on=['Month','Year'])\n",
    "wrg_final.index = pd.to_datetime(wrg_final['Year'].astype(str) + '-' + wrg_final['Month'], format='%Y-%b')\n",
    "wrg_final.drop(['Year', 'Month'], axis=1, inplace=True)\n",
    "wrg_final=wrg_final.sort_index()\n",
    "wrg_final['2016':'2021']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_=wrg_final.iloc[:,:-1]\n",
    "y=wrg_final.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalling the Data to improve model perfomance and bring features into similar range\n",
    "ss=StandardScaler()\n",
    "X=ss.fit_transform(X_)\n",
    "X=pd.DataFrame(X,columns=wrg_final.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=66,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfoming Hyper-parameter tuning with comparison with other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing Parameters\n",
    "\n",
    "rf_params = {'n_estimators': [500,300,100,800,1000], 'max_depth': [12,15,10,5,7,3]}\n",
    "\n",
    "lr_param_grid = {}\n",
    "\n",
    "svr_param_grid = {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create models\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "lr_model = LinearRegression()\n",
    "svr_model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create GridSearchCV objects\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, cv=5)\n",
    "lr_grid = GridSearchCV(lr_model, lr_param_grid)\n",
    "svr_grid = GridSearchCV(svr_model, svr_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVR(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10],\n",
       "                         'kernel': ['linear', 'rbf']})"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the models\n",
    "rf_grid.fit(X_train, y_train)\n",
    "lr_grid.fit(X_train, y_train)\n",
    "svr_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best hyperparameters\n",
    "rf_best_params = rf_grid.best_params_\n",
    "lr_best_params = lr_grid.best_params_\n",
    "svr_best_params = svr_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new models with the best hyperparameters\n",
    "rf_best_model = RandomForestRegressor(**rf_best_params, random_state=42)\n",
    "lr_best_model = LinearRegression(**lr_best_params)\n",
    "svr_best_model = SVR(**svr_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=10, gamma=0.1)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the best models\n",
    "rf_best_model.fit(X_train, y_train)\n",
    "lr_best_model.fit(X_train, y_train)\n",
    "svr_best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "rf_preds = rf_best_model.predict(X_test)\n",
    "lr_preds = lr_best_model.predict(X_test)\n",
    "svr_preds = svr_best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking individual model performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R2 Score: 0.9652738831657484\n",
      "Linear Regression R2 Score: 0.9735753246167103\n",
      "Support Vector Regressor R2 Score: 0.9840841642253106\n"
     ]
    }
   ],
   "source": [
    "# calculate r2 scores\n",
    "\n",
    "rf_r2 = r2_score(y_test, rf_preds)\n",
    "print(f\"Random Forest R2 Score: {rf_r2}\")\n",
    "\n",
    "lr_r2 = r2_score(y_test, lr_preds)\n",
    "print(f\"Linear Regression R2 Score: {lr_r2}\")\n",
    "\n",
    "svr_r2 = r2_score(y_test, svr_preds)\n",
    "print(f\"Support Vector Regressor R2 Score: {svr_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Ridge and Lasso Regression and cross validation to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "rf = RandomForestRegressor()\n",
    "svr = SVR()\n",
    "\n",
    "lr_params = {'normalize': [True, False]}\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "lasso_params = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "rf_params = {'n_estimators': [500,300,100,800,1000], 'max_depth':[12,15,10,5,7,3] }\n",
    "svr_params = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Linear Regression': (lr, lr_params),\n",
    "          'Ridge Regression': (ridge, ridge_params),\n",
    "          'Lasso Regression': (lasso, lasso_params),\n",
    "          'Random Forest Regression': (rf, rf_params),\n",
    "          'Support Vector Regression': (svr, svr_params)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.995 (±0.003)\n",
      "Ridge Regression: 0.995 (±0.002)\n",
      "Lasso Regression: 0.996 (±0.001)\n",
      "Random Forest Regression: 0.719 (±0.082)\n",
      "Support Vector Regression: 0.992 (±0.002)\n"
     ]
    }
   ],
   "source": [
    "models = {'Linear Regression': (lr, lr_params),\n",
    "          'Ridge Regression': (ridge, ridge_params),\n",
    "          'Lasso Regression': (lasso, lasso_params),\n",
    "          'Random Forest Regression': (rf, rf_params),\n",
    "          'Support Vector Regression': (svr, svr_params)}\n",
    "for name, (model, params) in models.items():\n",
    "    gs = GridSearchCV(model, params, cv=2,n_jobs=-1)\n",
    "    scores = cross_val_score(gs, X_test, y_test, cv=2, scoring='r2')\n",
    "    print(f'{name}: {scores.mean():.3f} (±{scores.std():.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing ensemble methods and full model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "f_pred=[]\n",
    "f_pred.append((rf_preds+lr_preds+svr_preds)/3)\n",
    "f_pred=np.array(f_pred)\n",
    "f_pred=f_pred.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R2 Score: 0.9828899398386829\n",
      " Mean Absolute Percentage Error: 0.014866089952342166\n",
      "Mean Squared Error : 0.014866089952342166\n"
     ]
    }
   ],
   "source": [
    "rr2 = r2_score(y_test, f_pred)\n",
    "print(f\" R2 Score: {rr2}\")\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, f_pred)\n",
    "print(f\" Mean Absolute Percentage Error: {mape}\")\n",
    "\n",
    "mse=mean_squared_error(y_test,f_pred)\n",
    "print(f\"Mean Squared Error : {mape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=[]\n",
    "for i in f_pred:\n",
    "    if (i>=0) and i<=50:\n",
    "        loc.append('Good')\n",
    "    elif i>=51 and i<=100:\n",
    "        loc.append('Moderate')\n",
    "    elif i>=101 and i<=150:\n",
    "        loc.append('Unhealthy for Sensitive Groups')\n",
    "    elif i>=151 and i<=200:\n",
    "        loc.append('Unhealthy')\n",
    "    elif i>=201 and i<=300:\n",
    "        loc.append('Very Unhealthy')\n",
    "    else:\n",
    "        loc.append('Hazardous')\n",
    "y_test=pd.DataFrame(y_test)\n",
    "y_test['Level of Concern']=loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AQI</th>\n",
       "      <th>Level of Concern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-01</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-01</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>68.041667</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>72.916667</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>72.514053</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>90.555556</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-01</th>\n",
       "      <td>58.250000</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>81.111111</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>60.080031</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>73.370370</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>94.000000</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>77.094650</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-01</th>\n",
       "      <td>51.666667</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>89.056130</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-01</th>\n",
       "      <td>76.057747</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>91.444444</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>93.074074</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>79.222222</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01</th>\n",
       "      <td>72.833333</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AQI Level of Concern\n",
       "2020-02-01  88.000000         Moderate\n",
       "2021-11-01  65.000000         Moderate\n",
       "2017-05-01  68.041667         Moderate\n",
       "2021-04-01  71.000000         Moderate\n",
       "2019-09-01  72.916667         Moderate\n",
       "2022-02-01  72.514053         Moderate\n",
       "2019-01-01  90.555556         Moderate\n",
       "2020-06-01  58.250000         Moderate\n",
       "2018-05-01  81.111111         Moderate\n",
       "2022-04-01  60.080031         Moderate\n",
       "2016-04-01  73.370370         Moderate\n",
       "2022-12-01  94.000000         Moderate\n",
       "2022-05-01  77.094650         Moderate\n",
       "2016-09-01  51.666667         Moderate\n",
       "2019-04-01  89.056130         Moderate\n",
       "2022-03-01  76.057747         Moderate\n",
       "2020-12-01  91.444444         Moderate\n",
       "2019-05-01  93.074074         Moderate\n",
       "2018-03-01  79.222222         Moderate\n",
       "2018-08-01  72.833333         Moderate"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(df):\n",
    "    df=ss.transform(df.values)\n",
    "    rfp=rf_best_model.predict(df)\n",
    "    lrp=lr_best_model.predict(df)\n",
    "    svrp=svr_best_model.predict(df)\n",
    "    f_pred=[]\n",
    "    f_pred.append((rfp+lrp+svrp)/3)\n",
    "    f_pred=np.array(f_pred)\n",
    "    f_pred=f_pred.reshape(-1,1)\n",
    "    loc=[]\n",
    "    for i in f_pred:\n",
    "        if (i>=0) and i<=50:\n",
    "            loc.append('Good')\n",
    "        elif i>=51 and i<=100:\n",
    "            loc.append('Moderate')\n",
    "        elif i>=101 and i<=150:\n",
    "            loc.append('Unhealthy for Sensitive Groups')\n",
    "        elif i>=151 and i<=200:\n",
    "            loc.append('Unhealthy')\n",
    "        elif i>=201 and i<=300:\n",
    "            loc.append('Very Unhealthy')\n",
    "        else:\n",
    "            loc.append('Hazardous')\n",
    "    df_p=pd.DataFrame(f_pred,columns=['AQI'])\n",
    "    df_p['AQI']=f_pred\n",
    "    df_p['Level of Concern']=np.array(loc).reshape(-1,1)\n",
    "    print(df_p)\n",
    "    return df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          AQI Level of Concern\n",
      "0   73.223204         Moderate\n",
      "1   73.214048         Moderate\n",
      "2   75.978603         Moderate\n",
      "3   61.504043         Moderate\n",
      "4   76.658215         Moderate\n",
      "5   84.378233         Moderate\n",
      "6   50.854867        Hazardous\n",
      "7   57.798713         Moderate\n",
      "8   51.990740         Moderate\n",
      "9   92.876397         Moderate\n",
      "10  92.684760         Moderate\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res=predictor(X_['2022'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.3908257373487176\n",
      "Mean Squared Error: 3.4696106266203333\n",
      "Mean Absolute Percentage: 0.024318528131646564\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Absolute Error:\",mean_absolute_error(y['2022'],res['AQI']))\n",
    "print(\"Mean Squared Error:\",mean_squared_error(y['2022'],res['AQI']))\n",
    "print('Mean Absolute Percentage:',mean_absolute_percentage_error(y['2022'],res['AQI']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>Jan</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jan</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>Jan</td>\n",
       "      <td>28.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>Jan</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>Jan</td>\n",
       "      <td>49.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2018</td>\n",
       "      <td>Dec</td>\n",
       "      <td>42.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2019</td>\n",
       "      <td>Dec</td>\n",
       "      <td>50.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2020</td>\n",
       "      <td>Dec</td>\n",
       "      <td>35.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2021</td>\n",
       "      <td>Dec</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2022</td>\n",
       "      <td>Dec</td>\n",
       "      <td>32.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year Month   NOX\n",
       "0   2016   Jan  26.0\n",
       "1   2017   Jan  25.0\n",
       "2   2018   Jan  28.5\n",
       "3   2019   Jan  54.5\n",
       "4   2020   Jan  49.2\n",
       "..   ...   ...   ...\n",
       "79  2018   Dec  42.1\n",
       "80  2019   Dec  50.5\n",
       "81  2020   Dec  35.2\n",
       "82  2021   Dec  31.0\n",
       "83  2022   Dec  32.6\n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrg_nox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting future Pollutant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrg_so2.index = pd.to_datetime(wrg_so2['Year'].astype(str) + '-' + wrg_so2['Month'], format='%Y-%b')\n",
    "wrg_so2.drop(['Year', 'Month'], axis=1, inplace=True)\n",
    "wrg_so2=wrg_so2.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains:  ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\braindedmemory\\Programming\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:510\u001b[0m, in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=508'>509</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=509'>510</a>\u001b[0m     values, tz \u001b[39m=\u001b[39m conversion\u001b[39m.\u001b[39;49mdatetime_to_datetime64(arg)\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=510'>511</a>\u001b[0m     dta \u001b[39m=\u001b[39m DatetimeArray(values, dtype\u001b[39m=\u001b[39mtz_to_dtype(tz))\n",
      "File \u001b[1;32mc:\\braindedmemory\\Programming\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx:360\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\braindedmemory\\CP\\Asscom\\Warangal\\warangal.ipynb Cell 42'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/braindedmemory/CP/Asscom/Warangal/warangal.ipynb#ch0000075?line=0'>1</a>\u001b[0m wrg_nox\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mto_datetime(wrg_nox[\u001b[39m'\u001b[39;49m\u001b[39mYear\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mastype(\u001b[39mstr\u001b[39;49m) \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m wrg_nox[\u001b[39m'\u001b[39;49m\u001b[39mMonth\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mY-\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/braindedmemory/CP/Asscom/Warangal/warangal.ipynb#ch0000075?line=1'>2</a>\u001b[0m wrg_nox\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMonth\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/braindedmemory/CP/Asscom/Warangal/warangal.ipynb#ch0000075?line=2'>3</a>\u001b[0m wrg_nox\u001b[39m=\u001b[39mwrg_nox\u001b[39m.\u001b[39msort_index()\n",
      "File \u001b[1;32mc:\\braindedmemory\\Programming\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1051\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=1048'>1049</a>\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mmap(cache_array)\n\u001b[0;32m   <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=1049'>1050</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=1050'>1051</a>\u001b[0m         values \u001b[39m=\u001b[39m convert_listlike(arg\u001b[39m.\u001b[39;49m_values, \u001b[39mformat\u001b[39;49m)\n\u001b[0;32m   <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=1051'>1052</a>\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39m_constructor(values, index\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mindex, name\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mname)\n\u001b[0;32m   <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=1052'>1053</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[39m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\braindedmemory\\Programming\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:394\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=390'>391</a>\u001b[0m         \u001b[39mformat\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=392'>393</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=393'>394</a>\u001b[0m     res \u001b[39m=\u001b[39m _to_datetime_with_format(\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=394'>395</a>\u001b[0m         arg, orig_arg, name, tz, \u001b[39mformat\u001b[39;49m, exact, errors, infer_datetime_format\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=395'>396</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=396'>397</a>\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=397'>398</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\braindedmemory\\Programming\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:514\u001b[0m, in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=511'>512</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m DatetimeIndex\u001b[39m.\u001b[39m_simple_new(dta, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=512'>513</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m--> <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=513'>514</a>\u001b[0m     \u001b[39mraise\u001b[39;00m err\n",
      "File \u001b[1;32mc:\\braindedmemory\\Programming\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:501\u001b[0m, in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=497'>498</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m _box_as_indexlike(result, utc\u001b[39m=\u001b[39mutc, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=499'>500</a>\u001b[0m     \u001b[39m# fallback\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=500'>501</a>\u001b[0m     res \u001b[39m=\u001b[39m _array_strptime_with_fallback(\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=501'>502</a>\u001b[0m         arg, name, tz, fmt, exact, errors, infer_datetime_format\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=502'>503</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=503'>504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=505'>506</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=506'>507</a>\u001b[0m     \u001b[39m# Fallback to try to convert datetime objects if timezone-aware\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=507'>508</a>\u001b[0m     \u001b[39m#  datetime objects are found without passing `utc=True`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\braindedmemory\\Programming\\anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:437\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=433'>434</a>\u001b[0m utc \u001b[39m=\u001b[39m tz \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mutc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=435'>436</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=436'>437</a>\u001b[0m     result, timezones \u001b[39m=\u001b[39m array_strptime(arg, fmt, exact\u001b[39m=\u001b[39;49mexact, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=437'>438</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mZ\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m fmt \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mz\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m fmt:\n\u001b[0;32m    <a href='file:///c%3A/braindedmemory/Programming/anaconda3/lib/site-packages/pandas/core/tools/datetimes.py?line=438'>439</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, tz, name)\n",
      "File \u001b[1;32mc:\\braindedmemory\\Programming\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:156\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unconverted data remains:  "
     ]
    }
   ],
   "source": [
    "wrg_nox.index = pd.to_datetime(wrg_nox['Year'].astype(str) + '-' + wrg_nox['Month'], format='%Y-%b')\n",
    "wrg_nox.drop(['Year', 'Month'], axis=1, inplace=True)\n",
    "wrg_nox=wrg_nox.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrg_pm10.index = pd.to_datetime(wrg_pm10['Year'].astype(str) + '-' + wrg_pm10['Month'], format='%Y-%b')\n",
    "wrg_pm10.drop(['Year', 'Month'], axis=1, inplace=True)\n",
    "wrg_pm10=wrg_pm10.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'niz_so2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\braindedmemory\\CP\\Asscom\\Warangal\\warangal.ipynb Cell 44'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/braindedmemory/CP/Asscom/Warangal/warangal.ipynb#ch0000077?line=0'>1</a>\u001b[0m \u001b[39m#Performing exponential smoothing for the data to predict future dependent variables\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/braindedmemory/CP/Asscom/Warangal/warangal.ipynb#ch0000077?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstatsmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtsa\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m ExponentialSmoothing\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/braindedmemory/CP/Asscom/Warangal/warangal.ipynb#ch0000077?line=3'>4</a>\u001b[0m model_so2\u001b[39m=\u001b[39m ExponentialSmoothing(niz_so2[:\u001b[39m'\u001b[39m\u001b[39m2020\u001b[39m\u001b[39m'\u001b[39m], trend\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madd\u001b[39m\u001b[39m'\u001b[39m, seasonal\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmul\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/braindedmemory/CP/Asscom/Warangal/warangal.ipynb#ch0000077?line=4'>5</a>\u001b[0m fit_so2 \u001b[39m=\u001b[39m model_so2\u001b[39m.\u001b[39mfit(optimized\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/braindedmemory/CP/Asscom/Warangal/warangal.ipynb#ch0000077?line=5'>6</a>\u001b[0m fore_so2 \u001b[39m=\u001b[39m fit_so2\u001b[39m.\u001b[39mforecast(\u001b[39m12\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'niz_so2' is not defined"
     ]
    }
   ],
   "source": [
    "#Performing exponential smoothing for the data to predict future dependent variables\n",
    "\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "model_so2= ExponentialSmoothing(wrg_so2[:'2020'], trend='add', seasonal='mul')\n",
    "fit_so2 = model_so2.fit(optimized=True)\n",
    "fore_so2 = fit_so2.forecast(12)\n",
    "\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "model_nox= ExponentialSmoothing(wrg_nox[:'2020'], trend='add', seasonal='mul')\n",
    "fit_nox = model_nox.fit(optimized=True)\n",
    "fore_nox = fit_nox.forecast(12)\n",
    "\n",
    "\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "model_pm10= ExponentialSmoothing(wrg_pm10[:'2020'], trend='add', seasonal='mul')\n",
    "fit_pm10 = model_pm10.fit(optimized=True)\n",
    "fore_pm10 = fit_pm10.forecast(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "from sklearn.metrics import mean_absolute_percentage_error,mean_absolute_error\n",
    "mae_so2 = mean_absolute_error(wrg_so2['2021'],fore_so2['2021'] )\n",
    "print('Mean Absolute Error for so2:', mae_so2)\n",
    "mae_nox = mean_absolute_error(wrg_nox['2022'],fore_nox )\n",
    "print('Mean Absolute Error for nox:', mae_nox)\n",
    "mae_pm10 = mean_absolute_error(wrg_pm10['2022'],fore_pm10 )\n",
    "print('MAPE for PM10:', mae_pm10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df=pd.DataFrame(fore_so2,columns=['SO2'])\n",
    "forecast_df['NOX']=fore_so2\n",
    "forecast_df['PM10']=fore_pm10\n",
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred=predictor(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred.to_csv('Nizamabad2023.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b124afded074c70b1168b021b33622efccdf1097854b00f22ff1bd7656ffa95"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
